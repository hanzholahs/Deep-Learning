{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "from utils import set_seed, _model_file, _config_file\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import KMNIST\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to store dataset and pretrained models\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/kuzushiju_mnist\")\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"models/kuzushiju_mnist\")\n",
    "\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for setting the seed from utils.py\n",
    "set_seed(123)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for used throughout this notebook\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = KMNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50_000, 10_000])\n",
    "test_set = KMNIST(root=DATASET_PATH, train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    train_set, batch_size=1024, shuffle=True, drop_last=False\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(val_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "\n",
    "test_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmp_imgs = [train_set[i][0] for i in range(16)]\n",
    "img_grid = torchvision.utils.make_grid(\n",
    "    torch.stack(exmp_imgs, dim=0), nrow=4, normalize=True, pad_value=0.5\n",
    ")\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"FashionMNIST examples\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lbl = next(iter(train_set))\n",
    "img.shape, lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape, hidden_units):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Linear(in_shape, hidden_units[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_units)-1):\n",
    "            layers += [nn.Linear(hidden_units[i], hidden_units[i+1]), nn.ReLU()]\n",
    "        layers += [nn.Linear(hidden_units[-1], out_shape)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.config = {\"in_shape\": in_shape, \"out_shape\": out_shape, \"hidden_units\": hidden_units}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ANN(784, 10, [64, 64, 32, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_shape, hidden_units):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc = ANN(64 * 5 * 5, out_shape, hidden_units)\n",
    "        self.config = {\"out_shape\": out_shape, \"hidden_units\": hidden_units}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(10, [64, 32, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, lbl in train_loader:\n",
    "    cnn(img)\n",
    "    ann(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loss_module, optimizer, train_loader=train_loader):\n",
    "    true_preds, loss_tracker = 0.0, 0.0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # update parameters\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = loss_module(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # track performance\n",
    "        true_preds += (preds.argmax(dim=-1) == y).sum()\n",
    "        loss_tracker += loss\n",
    "    train_loss = loss_tracker / len(train_loader)\n",
    "    train_acc = true_preds / len(train_set)\n",
    "    return train_acc.item(), train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(model, loss_module, val_loader=val_loader):\n",
    "    true_preds, loss_tracker = 0.0, 0.0\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # make predictions\n",
    "            preds = model(X)\n",
    "            loss = loss_module(preds, y)\n",
    "            # track performance\n",
    "            true_preds += (preds.argmax(dim=-1) == y).sum()\n",
    "            loss_tracker += loss\n",
    "    val_loss = loss_tracker / len(val_loader)\n",
    "    val_acc = true_preds / len(val_set)\n",
    "    return val_acc.item(), val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, model_name, Network):\n",
    "    import json\n",
    "    config_file, model_file = _config_file(model_path, model_name), _model_file(model_path, model_name)\n",
    "    if not os.path.isfile(config_file) or not os.path.isfile(model_file):\n",
    "        raise Exception(f\"Could not find the config file: {config_file} or model file: {model_file}.\")\n",
    "    with open(config_file) as f:\n",
    "        config_dict = json.load(f)\n",
    "    model = Network(**config_dict)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    return model\n",
    "\n",
    "def save_model(model, model_path, model_name):\n",
    "    import json\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    config_file, model_file = _config_file(model_path, model_name), _model_file(model_path, model_name)\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(model.config, f)\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, train_loader, val_loader, epochs = 30, patience = 7, overwrite = False):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    train_acc_tracker, train_loss_tracker = [], []\n",
    "    val_acc_tracker, val_loss_tracker = [], []\n",
    "    best_val_epoch = -1\n",
    "\n",
    "    file_exists = os.path.isfile(_model_file(CHECKPOINT_PATH, model_name))\n",
    "    if file_exists and not overwrite:\n",
    "        print(f\"Model file {model_name} already exists. Skip training.\")\n",
    "        model = load_model(CHECKPOINT_PATH, model_name, model.__class__)\n",
    "        return model\n",
    "\n",
    "    for epoch in range(1, 1+epochs):\n",
    "        train_acc, train_loss = train_step(model, loss_module, optimizer, train_loader)\n",
    "        val_acc, val_loss = val_step(model, loss_module, val_loader)\n",
    "        \n",
    "        print(f\"[{epoch}/{epochs}]\", end=\" \")\n",
    "        print(f\"train_acc: {train_acc:.4f}; train_loss: {train_loss:.4f};\", end=\" \")\n",
    "        print(f\"val_acc: {val_acc:.4f}; val_loss: {val_loss:.4f};\")\n",
    "\n",
    "        train_acc_tracker.append(train_acc)\n",
    "        train_loss_tracker.append(train_loss)\n",
    "        val_acc_tracker.append(val_acc)\n",
    "        val_loss_tracker.append(val_loss)\n",
    "\n",
    "        if len(val_acc_tracker) <= 1 or val_acc > val_acc_tracker[best_val_epoch]:\n",
    "            model.config[\"train_acc\"] = train_acc_tracker\n",
    "            model.config[\"train_loss\"] = train_loss_tracker\n",
    "            model.config[\"val_acc\"] = val_acc_tracker\n",
    "            model.config[\"val_loss\"] = val_loss_tracker\n",
    "            best_val_epoch = epoch\n",
    "            save_model(model, CHECKPOINT_PATH, model_name)\n",
    "        elif best_val_epoch <= epoch - patience:\n",
    "            print(f\"Early stopping at {epoch} epochs\")\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = train(ann, \"KMNIST_ANN\", train_loader, val_loader, epochs=25, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = train(cnn, \"KMNIST_CNN\", train_loader, val_loader, epochs=25, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(model, metric, model_name = \"Neural Network Model\"):\n",
    "    if metric not in [\"acc\", \"loss\"]:\n",
    "        raise Exception(\"`metric` must be either 'acc' or 'loss'\")\n",
    "    metric_name = \"Accuracy\" if metric == \"acc\" else \"Loss\"\n",
    "    train_scores = model.config[f\"train_{metric}\"]\n",
    "    val_scores = model.config[f\"val_{metric}\"]\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(5, 3))  # width: 10 inches, height: 6 inches\n",
    "    plt.plot([i for i in range(1, len(train_scores) + 1)], train_scores, color=\"blue\", label=\"Train\")\n",
    "    plt.plot([i for i in range(1, len(val_scores) + 1)], val_scores, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"Training and Validation {metric_name} of {model_name}\")\n",
    "    plt.legend() \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(ann, \"acc\", \"ANN Model\")\n",
    "plot_training(ann, \"loss\", \"ANN Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(cnn, \"acc\", \"CNN Model\")\n",
    "plot_training(ann, \"loss\", \"CNN Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_module=None):\n",
    "    if loss_module is None:\n",
    "        loss_module = nn.CrossEntropyLoss()\n",
    "    true_preds, loss_tracker = 0.0, 0.0\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # make predictions\n",
    "            preds = model(X)\n",
    "            loss = loss_module(preds, y)\n",
    "            # track performance\n",
    "            true_preds += (preds.argmax(dim=-1) == y).sum()\n",
    "            loss_tracker += loss\n",
    "    test_loss = loss_tracker / len(test_loader)\n",
    "    test_acc = true_preds / len(test_set)\n",
    "    return test_acc.item(), test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss = test_model(ann, test_loader)\n",
    "print(f\"The ANN model achieved an accuracy of {100*acc:.2f}% with a corresponding loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss = test_model(cnn, test_loader)\n",
    "print(f\"The CNN model achieved an accuracy of {100*acc:.2f}% with a corresponding loss of {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
